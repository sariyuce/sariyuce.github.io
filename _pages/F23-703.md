---
layout: page
permalink: /F23-703/
title:
description:
nav: false
---


<h1>CSE 703: Deep Learning on Graphs (Fall 23)</h1>
<TABLE border="0" align="left" >
<TR><TD> Instructor: 	<TD> <b>A. Erdem Sariyuce (erdem AT buffalo.edu)</b>   </TD></TD></TR>
<TR><TD>Class hours: <TD> Wed 5:00-7:00, Davis 113A </TD></TD></TR>
<TR><TD>Office hours: <TD> Thu 10:00-12:00, Davis 323 </TD></TD></TR>
</TABLE>

<h2>Course Description</h2>
<p>Graphs are everywhere. Their scale, rate of change, and the irregular nature pose many new challenges. Deep learning has been shown to be successful in a number of domains, ranging from images to natural language processing. However, applying deep learning to the ubiquitous graph data is non-trivial because of the unique characteristics. This seminar course covers recent papers in the last few years about deep learning on graphs. We will consider graph embeddings, knowledge graphs, graph kernels, graph neural networks, graph convolutional networks, graph adversarial methods. Students will learn the literature on deep learning on graphs, understand the state-of-the-art algorithms on various problems, and be familiar with the recent trends.</p>

<h2>Prerequisites</h2>
<p>It is assumed that students have a solid background on discrete mathematics and algorithms. Basic research skills like paper reading, critical thinking, problem solving, report writing, communication, and presentation are important as well.</p>


<h2>Grading Policy (Same for 1, 2, or 3 credits)</h2>
<ul>
<li> Serving as an <b>explainer</b> (one time): 34 pts</li>
<li> Serving as a <b>listener</b> (11 times) :  11*6 = 66 pts</li>
</ul>


<p>The final grade is S/U and <b>80 pts score is needed for an S. </b></p>

<h2>Paper presentation & questions</h2>
<p><b>Explainer role:</b> Each week there will be 1 or 2 <b>explainers</b>. Those students are responsible for presenting the paper and answering the student questions on Piazza. At the beginning of the class, the instructor will pick the presenter among those explainers. All explainers must be ready to present. Assignment of the explainers to the papers will be done by the instructor.</p>

<p><b>Listener role:</b> Each week all the students are supposed to read the paper of the week. All students, except explainers, serve as <b>listeners</b> and will ask <b>a unique question (one question, not less, not more)</b> on Piazza. Those questions will be answered by the explainers on Piazza and some questions will be selected by them for discussion in class. Questions should be open-ended and provide ground for class discussions, i.e., 'can you explain alg 1?' is not that kind of question. Questions should be posted to Piazza by Monday night, 11.59 pm EST.</p>

<h2> <a href = "https://piazza.com/buffalo/fall2023/cse703"> Piazza page</a></h2>


<h2>Schedule</h2>
<ul>

<li>Aug 30: <br>
    <b>
        Course overview by instructor <a href="../pdf/703-F23.pdf">[pdf]</a>
    </b>
    <br><br>

</li>



<li>Sep 6: <br>
<b>
    <a href="https://www.jmlr.org/papers/volume23/20-852/20-852.pdf">Machine Learning on Graphs: A Model and Comprehensive Taxonomy</a> Journal of Machine Learning Research 23 (2022) 1-64
</b>
<em>by Jason</em><br><br>
</li>



<li>Sep 13: <br>
<b>
    <a href="http://www.perozzi.net/publications/14_kdd_deepwalk.pdf">DeepWalk: Online Learning of Social Representations</a> SIGKDD 2014
</b>
<em>by Sumanth and Darryl</em><br><br>
</li>



<li>Sep 20: <br>
<b>
    <a href="http://proceedings.mlr.press/v48/yanga16.pdf">Revisiting Semi-Supervised Learning with Graph Embeddings</a> ICML 2016
</b>
<em>by Jasleen and Michael</em><br><br>
</li>



<li>Sep 27: <br>
<b>
    <a href="https://dl.acm.org/doi/10.1145/3159652.3159706">Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec</a> WSDM 2018
</b>
<em>by Yadvender and Atul</em><br><br>
</li>



<li>Oct 4: <br>
<b>
    <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/18067/17870">MILE: A Multi-Level Framework for Scalable Graph Embedding</a> ICWSM 2021
</b>
<em>by Aviral and Vrashi</em><br><br>
</li>



<li>Oct 11: <br>
<b>
    <a href="https://dl.acm.org/doi/10.1145/3580305.3599321">Efficient and Effective Edge-wise Graph Representation Learning</a> SIGKDD 2023
</b>
<em>by Avinash</em><br><br>
</li>



<li>Oct 18: <br>
<b>
    <a href="https://openreview.net/forum?id=SJU4ayYgl">Semi-supervised Classification with Graph Convolutional Networks</a> ICLR 2017
</b>
<em>by Rohith and Haritha</em><br><br>
</li>



<li>Oct 25: <br>
<b>
    <a href="https://proceedings.neurips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html">Inductive Representation Learning on Large Graphs</a> NIPS 2017
</b>
<em>by Sai and Priyanka</em><br><br>
</li>



<li>Nov 1: <br>
<b>
    <a href="https://openreview.net/forum?id=rJXMpikCZ">Graph Attention Networks</a> ICLR 2018
</b>
<em>by Debasmit and Shubham</em><br><br>
</li>



<li>Nov 8: <br>
<b>
    <a href="https://openreview.net/forum?id=rklz9iAcKQ">Deep Graph Infomax</a> ICLR 2019
</b>
<em>by Swaminathan</em><br><br>
</li>



<li>Nov 15: <br>
<b>
    <a href="https://arxiv.org/abs/1810.02244">Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks</a> AAAI 2019
</b>
<em>by Chris</em><br><br>
</li>



<li>Nov 29: <br>
<b>
    <a href="https://proceedings.neurips.cc/paper/2020/hash/58ae23d878a47004366189884c2f8440-Abstract.html">Beyond Homophily in Graph Neural Networks: Current Limitations and Effective Designs</a> NeurIPS 2020
</b>
<em>by Ram and Chirun</em><br><br>
</li>



<li>Dec 6: <br>
<b>
    <a href="https://openreview.net/forum?id=8E1-f3VhX1o">Combining Label Propagation and Simple Models Out-performs Graph Neural Networks</a> ICLR 2021
</b>
<em>by Lakshya</em><br><br>
</li>


</ul>
